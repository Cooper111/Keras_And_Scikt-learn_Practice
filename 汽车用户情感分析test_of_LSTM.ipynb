{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import jieba\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "raw_data = pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content_id</th>\n",
       "      <th>content</th>\n",
       "      <th>subject</th>\n",
       "      <th>sentiment_value</th>\n",
       "      <th>sentiment_word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>vUXizsqexyZVRdFH</td>\n",
       "      <td>因为森林人即将换代，这套系统没必要装在一款即将换代的车型上，因为肯定会影响价格。</td>\n",
       "      <td>价格</td>\n",
       "      <td>0</td>\n",
       "      <td>影响</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4QroPd9hNfnCHVt7</td>\n",
       "      <td>四驱价格貌似挺高的，高的可以看齐XC60了，看实车前脸有点违和感。不过大众的车应该不会差。</td>\n",
       "      <td>价格</td>\n",
       "      <td>-1</td>\n",
       "      <td>高</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>QmqJ2AvM5GplaRyz</td>\n",
       "      <td>斯柯达要说质量，似乎比大众要好一点，价格也低一些，用料完全一样。我听说过野帝，但没听说过你说...</td>\n",
       "      <td>价格</td>\n",
       "      <td>1</td>\n",
       "      <td>低</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>KMT1gFJiU4NWrVDn</td>\n",
       "      <td>这玩意都是给有钱任性又不懂车的土豪用的，这价格换一次我妹夫EP020可以换三锅了</td>\n",
       "      <td>价格</td>\n",
       "      <td>-1</td>\n",
       "      <td>有钱任性</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>nVIlGd5yMmc37t1o</td>\n",
       "      <td>17价格忒高，估计也就是14-15左右。</td>\n",
       "      <td>价格</td>\n",
       "      <td>-1</td>\n",
       "      <td>高</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         content_id                                            content  \\\n",
       "0  vUXizsqexyZVRdFH           因为森林人即将换代，这套系统没必要装在一款即将换代的车型上，因为肯定会影响价格。   \n",
       "1  4QroPd9hNfnCHVt7      四驱价格貌似挺高的，高的可以看齐XC60了，看实车前脸有点违和感。不过大众的车应该不会差。   \n",
       "2  QmqJ2AvM5GplaRyz  斯柯达要说质量，似乎比大众要好一点，价格也低一些，用料完全一样。我听说过野帝，但没听说过你说...   \n",
       "3  KMT1gFJiU4NWrVDn           这玩意都是给有钱任性又不懂车的土豪用的，这价格换一次我妹夫EP020可以换三锅了   \n",
       "4  nVIlGd5yMmc37t1o                            17价格忒高，估计也就是14-15左右。      \n",
       "\n",
       "  subject  sentiment_value sentiment_word  \n",
       "0      价格                0             影响  \n",
       "1      价格               -1              高  \n",
       "2      价格                1              低  \n",
       "3      价格               -1           有钱任性  \n",
       "4      价格               -1              高  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "word_change = list(raw_data['subject'].value_counts().keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'动力': 0, '价格': 1, '油耗': 2, '操控': 3, '舒适性': 4, '配置': 5, '安全性': 6, '内饰': 7, '外观': 8, '空间': 9}\n"
     ]
    }
   ],
   "source": [
    "word_dict = {}\n",
    "for i in range(10):\n",
    "    word_dict[word_change[i]] = i\n",
    "\n",
    "print(word_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# for i,text in enumerate(raw_data['subject']):\n",
    "#     raw_data['subject'][i] = word_dict[ raw_data['subject'][i] ]\n",
    "\n",
    "raw_data['subject'] = raw_data['subject'].apply(lambda x: word_dict[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      1\n",
       "1      1\n",
       "2      1\n",
       "3      1\n",
       "4      1\n",
       "5      1\n",
       "6      1\n",
       "7      1\n",
       "8      1\n",
       "9      1\n",
       "10     1\n",
       "11     1\n",
       "12     1\n",
       "13     1\n",
       "14     1\n",
       "15     1\n",
       "16     1\n",
       "17     1\n",
       "18     1\n",
       "19     1\n",
       "20     1\n",
       "21     1\n",
       "22     1\n",
       "23     1\n",
       "24     1\n",
       "25     1\n",
       "26     1\n",
       "27     1\n",
       "28     1\n",
       "29     1\n",
       "      ..\n",
       "470    0\n",
       "471    0\n",
       "472    4\n",
       "473    5\n",
       "474    3\n",
       "475    8\n",
       "476    4\n",
       "477    2\n",
       "478    1\n",
       "479    6\n",
       "480    6\n",
       "481    2\n",
       "482    1\n",
       "483    2\n",
       "484    9\n",
       "485    3\n",
       "486    8\n",
       "487    1\n",
       "488    1\n",
       "489    8\n",
       "490    8\n",
       "491    6\n",
       "492    0\n",
       "493    2\n",
       "494    0\n",
       "495    4\n",
       "496    1\n",
       "497    0\n",
       "498    1\n",
       "499    0\n",
       "Name: subject, Length: 500, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data['subject'].head(500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content_id</th>\n",
       "      <th>content</th>\n",
       "      <th>subject</th>\n",
       "      <th>sentiment_value</th>\n",
       "      <th>sentiment_word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>I2Oc8UfrTWj1Zsu5</td>\n",
       "      <td>15年6月以后生产的森林人与傲虎基本上都不烧机油。我也是摩托迷骑川崎小火神与雅马哈巧格，现在...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>NV5nHkQKyTXLdpGU</td>\n",
       "      <td>那这个价格还可以的，一般都是在15万上下</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>dqv5zaI1OZeERuwG</td>\n",
       "      <td>这个问题我觉得是这样：在滑行时发动机喷油嘴默认是不喷油的，但是当发动机怠速太低的时候，会恢复...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           content_id                                            content  \\\n",
       "497  I2Oc8UfrTWj1Zsu5  15年6月以后生产的森林人与傲虎基本上都不烧机油。我也是摩托迷骑川崎小火神与雅马哈巧格，现在...   \n",
       "498  NV5nHkQKyTXLdpGU                            那这个价格还可以的，一般都是在15万上下      \n",
       "499  dqv5zaI1OZeERuwG  这个问题我觉得是这样：在滑行时发动机喷油嘴默认是不喷油的，但是当发动机怠速太低的时候，会恢复...   \n",
       "\n",
       "     subject  sentiment_value sentiment_word  \n",
       "497        0                0            NaN  \n",
       "498        1                0            NaN  \n",
       "499        0                0            NaN  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data[497:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache C:\\Users\\Kavin\\AppData\\Local\\Temp\\jieba.cache\n",
      "Loading model cost 0.766 seconds.\n",
      "Prefix dict has been built succesfully.\n"
     ]
    }
   ],
   "source": [
    "raw_data['content'] = pd.Series([' '.join(jieba.cut(i, cut_all=True)) for i in raw_data['content']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    因为 森林 人 即将 换代   这 套 系统 没 必要 装 在 一款 即将 换代 的 车型 ...\n",
       "1    四 驱 价格 貌似 挺 高 的   高 的 可以 看齐 XC60 了   看 实 车 前 脸...\n",
       "2    斯柯达 柯达 要说 质量   似乎 比 大众 要 好 一点   价格 也 低 一些   用料...\n",
       "3    这 玩意 都 是 给 有钱 任性 又 不 懂 车 的 土豪 用 的   这 价格 换 一次 ...\n",
       "4                    17 价格 忒 高   估计 也 就是 14 15 左右     \n",
       "Name: content, dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data['content'].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "1   -1\n",
       "Name: sentiment_value, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data['sentiment_value'].head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content_id</th>\n",
       "      <th>content</th>\n",
       "      <th>subject</th>\n",
       "      <th>sentiment_value</th>\n",
       "      <th>sentiment_word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>vUXizsqexyZVRdFH</td>\n",
       "      <td>因为 森林 人 即将 换代   这 套 系统 没 必要 装 在 一款 即将 换代 的 车型 ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>影响</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4QroPd9hNfnCHVt7</td>\n",
       "      <td>四 驱 价格 貌似 挺 高 的   高 的 可以 看齐 XC60 了   看 实 车 前 脸...</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>高</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>QmqJ2AvM5GplaRyz</td>\n",
       "      <td>斯柯达 柯达 要说 质量   似乎 比 大众 要 好 一点   价格 也 低 一些   用料...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>低</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>KMT1gFJiU4NWrVDn</td>\n",
       "      <td>这 玩意 都 是 给 有钱 任性 又 不 懂 车 的 土豪 用 的   这 价格 换 一次 ...</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>有钱任性</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>nVIlGd5yMmc37t1o</td>\n",
       "      <td>17 价格 忒 高   估计 也 就是 14 15 左右</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>高</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         content_id                                            content  \\\n",
       "0  vUXizsqexyZVRdFH  因为 森林 人 即将 换代   这 套 系统 没 必要 装 在 一款 即将 换代 的 车型 ...   \n",
       "1  4QroPd9hNfnCHVt7  四 驱 价格 貌似 挺 高 的   高 的 可以 看齐 XC60 了   看 实 车 前 脸...   \n",
       "2  QmqJ2AvM5GplaRyz  斯柯达 柯达 要说 质量   似乎 比 大众 要 好 一点   价格 也 低 一些   用料...   \n",
       "3  KMT1gFJiU4NWrVDn  这 玩意 都 是 给 有钱 任性 又 不 懂 车 的 土豪 用 的   这 价格 换 一次 ...   \n",
       "4  nVIlGd5yMmc37t1o                  17 价格 忒 高   估计 也 就是 14 15 左右        \n",
       "\n",
       "   subject  sentiment_value sentiment_word  \n",
       "0        1                0             影响  \n",
       "1        1               -1              高  \n",
       "2        1                1              低  \n",
       "3        1               -1           有钱任性  \n",
       "4        1               -1              高  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9947\n",
      "9947\n"
     ]
    }
   ],
   "source": [
    "data = []\n",
    "label = []\n",
    "\n",
    "for i in raw_data['content']:\n",
    "    data.append(i)\n",
    "    \n",
    "for j in raw_data['sentiment_value']:\n",
    "    label.append(j)\n",
    "\n",
    "print(len(data))\n",
    "print(len(label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'因为 森林 人 即将 换代   这 套 系统 没 必要 装 在 一款 即将 换代 的 车型 上   因为 肯定 定会 影响 价格  '"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 16494 unique tokens.\n",
      "Shape of data tensor: (9947, 30)\n",
      "Shape of label tensor: (9947,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[175,\n",
       " 12,\n",
       " 8,\n",
       " 4560,\n",
       " 657,\n",
       " 50,\n",
       " 492,\n",
       " 339,\n",
       " 30,\n",
       " 445,\n",
       " 200,\n",
       " 23,\n",
       " 1116,\n",
       " 4560,\n",
       " 657,\n",
       " 1,\n",
       " 284,\n",
       " 64,\n",
       " 175,\n",
       " 136,\n",
       " 1498,\n",
       " 288,\n",
       " 24]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#处理文本为序列的整数列表，制作x，y\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "import numpy as np\n",
    "\n",
    "maxlen = 30\n",
    "training_sample = 7957\n",
    "validation_samples = 1990\n",
    "max_words = 10000\n",
    "#max_words个单词的文本转数值转换器\n",
    "tokenizer = Tokenizer(num_words=max_words, lower=False)\n",
    "tokenizer.fit_on_texts(data)\n",
    "#将字符串转化为整数索引的列表\n",
    "sequences = tokenizer.texts_to_sequences(data)#如果model=‘bianry’则是01表示\n",
    "#获得  字符：数字 的字典\n",
    "word_index = tokenizer.word_index\n",
    "print('Found %s unique tokens.' % len(word_index))\n",
    "#将列表转换为（samples，maxlen）的二维整数张量\n",
    "data = pad_sequences(sequences, maxlen=maxlen)#maxlen设置最大的序列长度，长于该长度的序列将会截短，短于该长度的序列将会填充\n",
    "#将结构数据转化为ndarray,一般是引用，不是copy对象\n",
    "labels = np.asarray(label)\n",
    "print('Shape of data tensor:', data.shape)\n",
    "print('Shape of label tensor:', labels.shape)\n",
    "sequences[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'的': 1,\n",
       " '了': 2,\n",
       " '是': 3,\n",
       " '我': 4,\n",
       " '2': 5,\n",
       " '也': 6,\n",
       " '就': 7,\n",
       " '人': 8,\n",
       " '都': 9,\n",
       " '车': 10,\n",
       " '你': 11,\n",
       " '森林': 12,\n",
       " '有': 13,\n",
       " '不': 14,\n",
       " '和': 15,\n",
       " '发动': 16,\n",
       " '动机': 17,\n",
       " '5': 18,\n",
       " '发动机': 19,\n",
       " '油耗': 20,\n",
       " '好': 21,\n",
       " '机油': 22,\n",
       " '在': 23,\n",
       " '价格': 24,\n",
       " '动力': 25,\n",
       " '可以': 26,\n",
       " '就是': 27,\n",
       " '没有': 28,\n",
       " '比': 29,\n",
       " '没': 30,\n",
       " '款': 31,\n",
       " '换': 32,\n",
       " '0': 33,\n",
       " '还是': 34,\n",
       " '吧': 35,\n",
       " '买': 36,\n",
       " '要': 37,\n",
       " '刹车': 38,\n",
       " '还': 39,\n",
       " '公里': 40,\n",
       " '个': 41,\n",
       " '说': 42,\n",
       " '这个': 43,\n",
       " '高': 44,\n",
       " '很': 45,\n",
       " '内饰': 46,\n",
       " '大': 47,\n",
       " '森': 48,\n",
       " '不是': 49,\n",
       " '这': 50,\n",
       " '用': 51,\n",
       " '看': 52,\n",
       " '感觉': 53,\n",
       " '四': 54,\n",
       " '烧': 55,\n",
       " '问题': 56,\n",
       " '多': 57,\n",
       " '开': 58,\n",
       " '会': 59,\n",
       " '什么': 60,\n",
       " '驱': 61,\n",
       " '空间': 62,\n",
       " '操控': 63,\n",
       " '上': 64,\n",
       " '配置': 65,\n",
       " '啊': 66,\n",
       " '一个': 67,\n",
       " '现在': 68,\n",
       " '去': 69,\n",
       " '斯巴鲁': 70,\n",
       " '巴鲁': 71,\n",
       " '如果': 72,\n",
       " '但是': 73,\n",
       " '高速': 74,\n",
       " '油': 75,\n",
       " '时': 76,\n",
       " '一样': 77,\n",
       " '跑': 78,\n",
       " '小': 79,\n",
       " '低': 80,\n",
       " '导航': 81,\n",
       " '对': 82,\n",
       " '吗': 83,\n",
       " '外观': 84,\n",
       " '但': 85,\n",
       " '不错': 86,\n",
       " '比较': 87,\n",
       " '那': 88,\n",
       " '底盘': 89,\n",
       " '觉得': 90,\n",
       " '能': 91,\n",
       " '变速': 92,\n",
       " '空调': 93,\n",
       " '过': 94,\n",
       " '全': 95,\n",
       " '性能': 96,\n",
       " '变速箱': 97,\n",
       " '应该': 98,\n",
       " '1': 99,\n",
       " '自己': 100,\n",
       " '到': 101,\n",
       " '万': 102,\n",
       " '保养': 103,\n",
       " '一点': 104,\n",
       " '优惠': 105,\n",
       " '的话': 106,\n",
       " '不过': 107,\n",
       " '4': 108,\n",
       " '一下': 109,\n",
       " '8': 110,\n",
       " '后': 111,\n",
       " '响': 112,\n",
       " '安全': 113,\n",
       " '知道': 114,\n",
       " '喜欢': 115,\n",
       " '差': 116,\n",
       " '左右': 117,\n",
       " '还有': 118,\n",
       " '时候': 119,\n",
       " '才': 120,\n",
       " '给': 121,\n",
       " '更': 122,\n",
       " '太': 123,\n",
       " '加': 124,\n",
       " '跟': 125,\n",
       " '店': 126,\n",
       " '3': 127,\n",
       " '再': 128,\n",
       " '虎': 129,\n",
       " '很多': 130,\n",
       " '不多': 131,\n",
       " '年': 132,\n",
       " '点': 133,\n",
       " '噪音': 134,\n",
       " '6': 135,\n",
       " '肯定': 136,\n",
       " '一般': 137,\n",
       " '可能': 138,\n",
       " '建议': 139,\n",
       " '等': 140,\n",
       " '配': 141,\n",
       " '舒适': 142,\n",
       " '不会': 143,\n",
       " '怎么': 144,\n",
       " '加速': 145,\n",
       " '又': 146,\n",
       " '正常': 147,\n",
       " '个人': 148,\n",
       " '有点': 149,\n",
       " '选': 150,\n",
       " '方向': 151,\n",
       " '所以': 152,\n",
       " '10': 153,\n",
       " '声音': 154,\n",
       " '傲': 155,\n",
       " '下': 156,\n",
       " '越野': 157,\n",
       " '前': 158,\n",
       " '而且': 159,\n",
       " '差不多': 160,\n",
       " '座椅': 161,\n",
       " '其他': 162,\n",
       " '万公里': 163,\n",
       " '中': 164,\n",
       " '不知': 165,\n",
       " '把': 166,\n",
       " '啥': 167,\n",
       " '4S': 168,\n",
       " '楼主': 169,\n",
       " '一': 170,\n",
       " '老': 171,\n",
       " '市区': 172,\n",
       " '确实': 173,\n",
       " '驾驶': 174,\n",
       " '因为': 175,\n",
       " '得': 176,\n",
       " '想': 177,\n",
       " '贵': 178,\n",
       " '后排': 179,\n",
       " '基本': 180,\n",
       " '做': 181,\n",
       " '便宜': 182,\n",
       " '7': 183,\n",
       " '多少': 184,\n",
       " '主要': 185,\n",
       " '看看': 186,\n",
       " '水平': 187,\n",
       " '新': 188,\n",
       " '16': 189,\n",
       " '这样': 190,\n",
       " '要是': 191,\n",
       " '版': 192,\n",
       " '方向盘': 193,\n",
       " '豪华': 194,\n",
       " '考虑': 195,\n",
       " '轮胎': 196,\n",
       " '新款': 197,\n",
       " '胎': 198,\n",
       " '进口': 199,\n",
       " '装': 200,\n",
       " '不如': 201,\n",
       " '其实': 202,\n",
       " '油门': 203,\n",
       " '呢': 204,\n",
       " '这车': 205,\n",
       " '已经': 206,\n",
       " '着': 207,\n",
       " '不要': 208,\n",
       " '一些': 209,\n",
       " '不好': 210,\n",
       " '估计': 211,\n",
       " '时间': 212,\n",
       " '除了': 213,\n",
       " '选择': 214,\n",
       " '途': 215,\n",
       " '这么': 216,\n",
       " '强': 217,\n",
       " '出来': 218,\n",
       " '省油': 219,\n",
       " '目前': 220,\n",
       " '置': 221,\n",
       " '那么': 222,\n",
       " '情况': 223,\n",
       " '13': 224,\n",
       " '不一': 225,\n",
       " '9': 226,\n",
       " '那个': 227,\n",
       " '起来': 228,\n",
       " '提': 229,\n",
       " '4s': 230,\n",
       " '国产': 231,\n",
       " '真的': 232,\n",
       " '需要': 233,\n",
       " '原厂': 234,\n",
       " '一直': 235,\n",
       " '性价比': 236,\n",
       " '直接': 237,\n",
       " '转速': 238,\n",
       " '从': 239,\n",
       " '12': 240,\n",
       " '不了': 241,\n",
       " '异': 242,\n",
       " '排量': 243,\n",
       " '试': 244,\n",
       " '让': 245,\n",
       " '挺': 246,\n",
       " '不能': 247,\n",
       " '不用': 248,\n",
       " '隔音': 249,\n",
       " '或者': 250,\n",
       " '升': 251,\n",
       " '明显': 252,\n",
       " '只是': 253,\n",
       " '踩': 254,\n",
       " '他': 255,\n",
       " '改': 256,\n",
       " '观': 257,\n",
       " '快': 258,\n",
       " '后备': 259,\n",
       " '后备箱': 260,\n",
       " '启动': 261,\n",
       " '非常': 262,\n",
       " '速': 263,\n",
       " '刹车片': 264,\n",
       " '只有': 265,\n",
       " '一次': 266,\n",
       " '最好': 267,\n",
       " '20': 268,\n",
       " '控': 269,\n",
       " '带': 270,\n",
       " '速度': 271,\n",
       " '是不是': 272,\n",
       " '平均': 273,\n",
       " '东西': 274,\n",
       " '舒适性': 275,\n",
       " '30': 276,\n",
       " '出': 277,\n",
       " '毛病': 278,\n",
       " '月': 279,\n",
       " '不到': 280,\n",
       " '之前': 281,\n",
       " '它': 282,\n",
       " '检查': 283,\n",
       " '车型': 284,\n",
       " '车子': 285,\n",
       " '最': 286,\n",
       " '奇': 287,\n",
       " '影响': 288,\n",
       " '品牌': 289,\n",
       " '找': 290,\n",
       " '感': 291,\n",
       " '档': 292,\n",
       " '18': 293,\n",
       " '当然': 294,\n",
       " '0T': 295,\n",
       " '力': 296,\n",
       " '原': 297,\n",
       " '么': 298,\n",
       " '发现': 299,\n",
       " '以上': 300,\n",
       " '只': 301,\n",
       " '新车': 302,\n",
       " '好像': 303,\n",
       " '方面': 304,\n",
       " '车身': 305,\n",
       " '刚': 306,\n",
       " '以后': 307,\n",
       " '来': 308,\n",
       " '两个': 309,\n",
       " '里': 310,\n",
       " '舒服': 311,\n",
       " '区别': 312,\n",
       " '系': 313,\n",
       " '纠结': 314,\n",
       " '使用': 315,\n",
       " '别的': 316,\n",
       " '显示': 317,\n",
       " '骏': 318,\n",
       " '路况': 319,\n",
       " '这种': 320,\n",
       " '安全性': 321,\n",
       " '一定': 322,\n",
       " '配件': 323,\n",
       " '以前': 324,\n",
       " '地方': 325,\n",
       " '下来': 326,\n",
       " '满意': 327,\n",
       " '与': 328,\n",
       " '行驶': 329,\n",
       " '车主': 330,\n",
       " '路': 331,\n",
       " '视野': 332,\n",
       " '不少': 333,\n",
       " '适合': 334,\n",
       " '特别': 335,\n",
       " '这些': 336,\n",
       " '欧蓝德': 337,\n",
       " '更换': 338,\n",
       " '系统': 339,\n",
       " '驾': 340,\n",
       " '自动': 341,\n",
       " 'SUV': 342,\n",
       " '别': 343,\n",
       " '11': 344,\n",
       " '城市': 345,\n",
       " '不大': 346,\n",
       " '第一': 347,\n",
       " '95': 348,\n",
       " '或': 349,\n",
       " '通过': 350,\n",
       " '被': 351,\n",
       " '更好': 352,\n",
       " '少': 353,\n",
       " '手动': 354,\n",
       " '不行': 355,\n",
       " '真': 356,\n",
       " '另外': 357,\n",
       " '然后': 358,\n",
       " '问': 359,\n",
       " '光': 360,\n",
       " '性': 361,\n",
       " 'suv': 362,\n",
       " '时尚': 363,\n",
       " '哪': 364,\n",
       " '够用': 365,\n",
       " '要求': 366,\n",
       " '增加': 367,\n",
       " '开始': 368,\n",
       " '动': 369,\n",
       " '风': 370,\n",
       " '感受': 371,\n",
       " '顶': 372,\n",
       " '开过': 373,\n",
       " '能力': 374,\n",
       " '提升': 375,\n",
       " '效果': 376,\n",
       " '走': 377,\n",
       " '15': 378,\n",
       " '经常': 379,\n",
       " '缺点': 380,\n",
       " '汽油': 381,\n",
       " '朋友': 382,\n",
       " '日本': 383,\n",
       " '只要': 384,\n",
       " '级别': 385,\n",
       " '好看': 386,\n",
       " '卖': 387,\n",
       " '噪': 388,\n",
       " '买车': 389,\n",
       " '达': 390,\n",
       " '习惯': 391,\n",
       " '混': 392,\n",
       " '质量': 393,\n",
       " '特': 394,\n",
       " '100': 395,\n",
       " '不同': 396,\n",
       " '原因': 397,\n",
       " '设计': 398,\n",
       " '120': 399,\n",
       " '转': 400,\n",
       " '操控性': 401,\n",
       " '只能': 402,\n",
       " '漆': 403,\n",
       " '行': 404,\n",
       " '综合': 405,\n",
       " '消耗': 406,\n",
       " '维修': 407,\n",
       " '国内': 408,\n",
       " '里面': 409,\n",
       " '长途': 410,\n",
       " '92': 411,\n",
       " '温度': 412,\n",
       " '完全': 413,\n",
       " '推荐': 414,\n",
       " '几个': 415,\n",
       " '毕竟': 416,\n",
       " '太多': 417,\n",
       " '停': 418,\n",
       " '够': 419,\n",
       " '该是': 420,\n",
       " '谢谢': 421,\n",
       " 'CVT': 422,\n",
       " '时速': 423,\n",
       " '来说': 424,\n",
       " '价位': 425,\n",
       " 'xv': 426,\n",
       " '14': 427,\n",
       " '不够': 428,\n",
       " '清洗': 429,\n",
       " '越': 430,\n",
       " '像': 431,\n",
       " '汉': 432,\n",
       " '用车': 433,\n",
       " '些': 434,\n",
       " '哈哈': 435,\n",
       " '我们': 436,\n",
       " '请': 437,\n",
       " '兰': 438,\n",
       " '热': 439,\n",
       " '保': 440,\n",
       " '反正': 441,\n",
       " '很大': 442,\n",
       " '关系': 443,\n",
       " '坐': 444,\n",
       " '必要': 445,\n",
       " '硬': 446,\n",
       " '接受': 447,\n",
       " 'XV': 448,\n",
       " '钱': 449,\n",
       " '尊贵': 450,\n",
       " '真心': 451,\n",
       " '汽车': 452,\n",
       " '元': 453,\n",
       " '出现': 454,\n",
       " '加油': 455,\n",
       " '放': 456,\n",
       " '内': 457,\n",
       " '容易': 458,\n",
       " '者': 459,\n",
       " '没什么': 460,\n",
       " '手机': 461,\n",
       " '二手': 462,\n",
       " '他们': 463,\n",
       " '自由': 464,\n",
       " '解决': 465,\n",
       " '轮毂': 466,\n",
       " '升级': 467,\n",
       " '自': 468,\n",
       " '功能': 469,\n",
       " '轿车': 470,\n",
       " '起步': 471,\n",
       " '宝马': 472,\n",
       " '烂': 473,\n",
       " '懂': 474,\n",
       " '送': 475,\n",
       " '无': 476,\n",
       " '担心': 477,\n",
       " '谁': 478,\n",
       " '灯': 479,\n",
       " '预算': 480,\n",
       " '原来': 481,\n",
       " '做工': 482,\n",
       " '软': 483,\n",
       " '完': 484,\n",
       " '怕': 485,\n",
       " '最后': 486,\n",
       " '绝对': 487,\n",
       " '平台': 488,\n",
       " '试试': 489,\n",
       " '合适': 490,\n",
       " '必须': 491,\n",
       " '套': 492,\n",
       " '论坛': 493,\n",
       " '长': 494,\n",
       " '虽然': 495,\n",
       " '还要': 496,\n",
       " '当时': 497,\n",
       " '参考': 498,\n",
       " '打': 499,\n",
       " '怠': 500,\n",
       " '实在': 501,\n",
       " '40': 502,\n",
       " '按': 503,\n",
       " '技术': 504,\n",
       " '变化': 505,\n",
       " '现款': 506,\n",
       " '日': 507,\n",
       " '实际': 508,\n",
       " '有些': 509,\n",
       " '行车': 510,\n",
       " '儿子': 511,\n",
       " '车辆': 512,\n",
       " '音响': 513,\n",
       " '5000': 514,\n",
       " '说明': 515,\n",
       " '控制': 516,\n",
       " '缸': 517,\n",
       " '同样': 518,\n",
       " '涡轮': 519,\n",
       " '还行': 520,\n",
       " '重': 521,\n",
       " '今天': 522,\n",
       " '降': 523,\n",
       " '如何': 524,\n",
       " '偏': 525,\n",
       " '听': 526,\n",
       " '先': 527,\n",
       " '最大': 528,\n",
       " '厉害': 529,\n",
       " '后来': 530,\n",
       " '关键': 531,\n",
       " '空气': 532,\n",
       " '急': 533,\n",
       " '脸': 534,\n",
       " '准备': 535,\n",
       " '本来': 536,\n",
       " '保险': 537,\n",
       " '大概': 538,\n",
       " '中国': 539,\n",
       " '提速': 540,\n",
       " '根本': 541,\n",
       " '路面': 542,\n",
       " 'XT': 543,\n",
       " '其它': 544,\n",
       " '开车': 545,\n",
       " '风口': 546,\n",
       " '安': 547,\n",
       " '看到': 548,\n",
       " '同级': 549,\n",
       " '需求': 550,\n",
       " '万多': 551,\n",
       " '运动': 552,\n",
       " '材料': 553,\n",
       " '后悔': 554,\n",
       " '大家': 555,\n",
       " '啦': 556,\n",
       " '不出': 557,\n",
       " '有关': 558,\n",
       " '冷': 559,\n",
       " '平时': 560,\n",
       " '叫': 561,\n",
       " '及': 562,\n",
       " '据说': 563,\n",
       " '哪里': 564,\n",
       " '有没有': 565,\n",
       " '2000': 566,\n",
       " '拆': 567,\n",
       " '牌': 568,\n",
       " '磨损': 569,\n",
       " '了解': 570,\n",
       " '算': 571,\n",
       " '出风口': 572,\n",
       " '是因为': 573,\n",
       " '为了': 574,\n",
       " '怎么样': 575,\n",
       " '听说': 576,\n",
       " '最近': 577,\n",
       " '搞': 578,\n",
       " '上下': 579,\n",
       " '一辆': 580,\n",
       " '公路': 581,\n",
       " '之后': 582,\n",
       " '车友': 583,\n",
       " '吸': 584,\n",
       " '超': 585,\n",
       " '护板': 586,\n",
       " '一万': 587,\n",
       " '各种': 588,\n",
       " '坏': 589,\n",
       " '是否': 590,\n",
       " '并': 591,\n",
       " '刹车盘': 592,\n",
       " '车盘': 593,\n",
       " '故障': 594,\n",
       " '秒': 595,\n",
       " 'crv': 596,\n",
       " '意思': 597,\n",
       " '上面': 598,\n",
       " '多公里': 599,\n",
       " '机滤': 600,\n",
       " '玻璃': 601,\n",
       " '实用': 602,\n",
       " '电动': 603,\n",
       " '网上': 604,\n",
       " '排气': 605,\n",
       " '80': 606,\n",
       " '优点': 607,\n",
       " '超车': 608,\n",
       " '稳定': 609,\n",
       " '庞大': 610,\n",
       " '逼': 611,\n",
       " '部分': 612,\n",
       " '电子': 613,\n",
       " '漏油': 614,\n",
       " '美国': 615,\n",
       " '提高': 616,\n",
       " '认为': 617,\n",
       " '至少': 618,\n",
       " '最低': 619,\n",
       " '花': 620,\n",
       " '而': 621,\n",
       " '偶尔': 622,\n",
       " '加热': 623,\n",
       " '位置': 624,\n",
       " '销售': 625,\n",
       " '原装': 626,\n",
       " '希望': 627,\n",
       " '安装': 628,\n",
       " '科': 629,\n",
       " '威': 630,\n",
       " '家用': 631,\n",
       " '车内': 632,\n",
       " '优势': 633,\n",
       " '尺寸': 634,\n",
       " '第二': 635,\n",
       " '一年': 636,\n",
       " '简单': 637,\n",
       " '方便': 638,\n",
       " '这款': 639,\n",
       " '同': 640,\n",
       " '足够': 641,\n",
       " '而已': 642,\n",
       " '前后': 643,\n",
       " '夏天': 644,\n",
       " '抖': 645,\n",
       " '较': 646,\n",
       " '入手': 647,\n",
       " '追求': 648,\n",
       " '百公里': 649,\n",
       " '严重': 650,\n",
       " '号': 651,\n",
       " '开起': 652,\n",
       " '超过': 653,\n",
       " 'Q5': 654,\n",
       " '根据': 655,\n",
       " '钥匙': 656,\n",
       " '换代': 657,\n",
       " '17': 658,\n",
       " '换过': 659,\n",
       " '地': 660,\n",
       " '静音': 661,\n",
       " '路上': 662,\n",
       " '启': 663,\n",
       " '0t': 664,\n",
       " '手刹': 665,\n",
       " '拉': 666,\n",
       " '后视': 667,\n",
       " '牛': 668,\n",
       " '真是': 669,\n",
       " '遇到': 670,\n",
       " 'cvt': 671,\n",
       " '办法': 672,\n",
       " '开关': 673,\n",
       " '差点': 674,\n",
       " '大灯': 675,\n",
       " '后期': 676,\n",
       " '件': 677,\n",
       " '较大': 678,\n",
       " '装甲': 679,\n",
       " '车况': 680,\n",
       " '稍微': 681,\n",
       " '还好': 682,\n",
       " '重要': 683,\n",
       " '刹车油': 684,\n",
       " '嘛': 685,\n",
       " '倒': 686,\n",
       " '亮': 687,\n",
       " '哪个': 688,\n",
       " '就算': 689,\n",
       " '差速': 690,\n",
       " '哦': 691,\n",
       " '卡': 692,\n",
       " '比如': 693,\n",
       " '熄火': 694,\n",
       " '费用': 695,\n",
       " '至于': 696,\n",
       " '相当': 697,\n",
       " '每次': 698,\n",
       " '里程': 699,\n",
       " '好多': 700,\n",
       " '不然': 701,\n",
       " '为什么': 702,\n",
       " '加装': 703,\n",
       " '车价': 704,\n",
       " '马自达': 705,\n",
       " '值': 706,\n",
       " '后视镜': 707,\n",
       " '门': 708,\n",
       " '黑': 709,\n",
       " '外面': 710,\n",
       " '自驾': 711,\n",
       " '合资': 712,\n",
       " '为': 713,\n",
       " '爽': 714,\n",
       " '模式': 715,\n",
       " '马力': 716,\n",
       " '不可': 717,\n",
       " '拿': 718,\n",
       " '如': 719,\n",
       " '太大': 720,\n",
       " '工作': 721,\n",
       " '滤芯': 722,\n",
       " '味道': 723,\n",
       " '度越': 724,\n",
       " '3000': 725,\n",
       " '尾': 726,\n",
       " '实话': 727,\n",
       " '靠': 728,\n",
       " '轻': 729,\n",
       " '挡': 730,\n",
       " '您': 731,\n",
       " '滤': 732,\n",
       " '指': 733,\n",
       " '50': 734,\n",
       " '轴承': 735,\n",
       " '定': 736,\n",
       " '60': 737,\n",
       " '可靠': 738,\n",
       " '停车': 739,\n",
       " '厂家': 740,\n",
       " '到底': 741,\n",
       " '店里': 742,\n",
       " '外形': 743,\n",
       " '排空': 744,\n",
       " '手车': 745,\n",
       " '咋': 746,\n",
       " '指南': 747,\n",
       " '段时间': 748,\n",
       " '弄': 749,\n",
       " '任何': 750,\n",
       " '两': 751,\n",
       " '白': 752,\n",
       " '低速': 753,\n",
       " '采纳': 754,\n",
       " '落地': 755,\n",
       " '本人': 756,\n",
       " '等等': 757,\n",
       " '差速器': 758,\n",
       " '下面': 759,\n",
       " '三': 760,\n",
       " '事': 761,\n",
       " '后轮': 762,\n",
       " '所谓': 763,\n",
       " '09': 764,\n",
       " '那种': 765,\n",
       " '下降': 766,\n",
       " '进口车': 767,\n",
       " '抖动': 768,\n",
       " '表': 769,\n",
       " '谈': 770,\n",
       " '十万': 771,\n",
       " '总': 772,\n",
       " '碳': 773,\n",
       " 'xt': 774,\n",
       " 'CRV': 775,\n",
       " '后面': 776,\n",
       " '注意': 777,\n",
       " '尤其': 778,\n",
       " '过弯': 779,\n",
       " '大众': 780,\n",
       " '月份': 781,\n",
       " 'ES': 782,\n",
       " '呀': 783,\n",
       " '小毛': 784,\n",
       " '小毛病': 785,\n",
       " '转向': 786,\n",
       " '昂': 787,\n",
       " '颜色': 788,\n",
       " '喷': 789,\n",
       " '兄弟': 790,\n",
       " '改装': 791,\n",
       " '不足': 792,\n",
       " '基本上': 793,\n",
       " '车上': 794,\n",
       " '请问': 795,\n",
       " '雷达': 796,\n",
       " '调': 797,\n",
       " '冬天': 798,\n",
       " '加上': 799,\n",
       " '纯': 800,\n",
       " '换机': 801,\n",
       " '火花': 802,\n",
       " '火花塞': 803,\n",
       " '修': 804,\n",
       " '对比': 805,\n",
       " '品质': 806,\n",
       " '电瓶': 807,\n",
       " '打开': 808,\n",
       " '屏幕': 809,\n",
       " '短': 810,\n",
       " '型号': 811,\n",
       " '最高': 812,\n",
       " '辆车': 813,\n",
       " '贴': 814,\n",
       " '关注': 815,\n",
       " '不在': 816,\n",
       " '码': 817,\n",
       " '二手车': 818,\n",
       " '高一': 819,\n",
       " '盘': 820,\n",
       " '美孚': 821,\n",
       " '25': 822,\n",
       " '呵呵': 823,\n",
       " '爆震': 824,\n",
       " '放心': 825,\n",
       " '唯一': 826,\n",
       " '体验': 827,\n",
       " '丰田': 828,\n",
       " '减震': 829,\n",
       " '该': 830,\n",
       " '数据': 831,\n",
       " '清楚': 832,\n",
       " '上去': 833,\n",
       " '对于': 834,\n",
       " '成本': 835,\n",
       " '具体': 836,\n",
       " '没事': 837,\n",
       " '有异': 838,\n",
       " '你好': 839,\n",
       " '市场': 840,\n",
       " '上市': 841,\n",
       " '天窗': 842,\n",
       " '现象': 843,\n",
       " '堵车': 844,\n",
       " '造成': 845,\n",
       " '积': 846,\n",
       " '省': 847,\n",
       " '慢': 848,\n",
       " '耐用': 849,\n",
       " '别人': 850,\n",
       " '点点': 851,\n",
       " '销量': 852,\n",
       " '麻烦': 853,\n",
       " '踩油门': 854,\n",
       " '值得': 855,\n",
       " '漂亮': 856,\n",
       " '塑料': 857,\n",
       " '轻度': 858,\n",
       " '恭喜': 859,\n",
       " '可': 860,\n",
       " '想买': 861,\n",
       " '之家': 862,\n",
       " '下班': 863,\n",
       " '出去': 864,\n",
       " '就要': 865,\n",
       " '说明书': 866,\n",
       " '有人': 867,\n",
       " '价钱': 868,\n",
       " '道': 869,\n",
       " '结果': 870,\n",
       " 'FB': 871,\n",
       " '在意': 872,\n",
       " '那些': 873,\n",
       " '再加': 874,\n",
       " '属于': 875,\n",
       " '一台': 876,\n",
       " '定要': 877,\n",
       " '裸': 878,\n",
       " '油温': 879,\n",
       " '度': 880,\n",
       " '盖': 881,\n",
       " '扭矩': 882,\n",
       " '北京': 883,\n",
       " '以及': 884,\n",
       " '上下班': 885,\n",
       " '之间': 886,\n",
       " '机': 887,\n",
       " '循环': 888,\n",
       " '一代': 889,\n",
       " '看来': 890,\n",
       " '真不': 891,\n",
       " '高度': 892,\n",
       " '里数': 893,\n",
       " '压': 894,\n",
       " '倒车': 895,\n",
       " '外': 896,\n",
       " '保持': 897,\n",
       " '片': 898,\n",
       " '告诉': 899,\n",
       " '气门': 900,\n",
       " '相对': 901,\n",
       " '界': 902,\n",
       " '免费': 903,\n",
       " '分钟': 904,\n",
       " '助力': 905,\n",
       " '豪': 906,\n",
       " '说实话': 907,\n",
       " '连': 908,\n",
       " '平衡': 909,\n",
       " '修理': 910,\n",
       " '反应': 911,\n",
       " '事故': 912,\n",
       " '一点点': 913,\n",
       " '不敢': 914,\n",
       " '换挡': 915,\n",
       " '降低': 916,\n",
       " '作用': 917,\n",
       " '不算': 918,\n",
       " '除非': 919,\n",
       " '线': 920,\n",
       " '千公里': 921,\n",
       " '差别': 922,\n",
       " '排座': 923,\n",
       " '的确': 924,\n",
       " '桶': 925,\n",
       " '油机': 926,\n",
       " '坑': 927,\n",
       " '换车': 928,\n",
       " '胶': 929,\n",
       " '保护': 930,\n",
       " '工时': 931,\n",
       " '貌似': 932,\n",
       " '次': 933,\n",
       " '这里': 934,\n",
       " '几次': 935,\n",
       " '山寨': 936,\n",
       " '保值': 937,\n",
       " '人家': 938,\n",
       " '哒': 939,\n",
       " '那里': 940,\n",
       " '主动': 941,\n",
       " '发': 942,\n",
       " '气滤': 943,\n",
       " '5T': 944,\n",
       " '专业': 945,\n",
       " '稳': 946,\n",
       " '算是': 947,\n",
       " '几万': 948,\n",
       " '二': 949,\n",
       " '普通': 950,\n",
       " '马': 951,\n",
       " '存在': 952,\n",
       " '奥迪': 953,\n",
       " '费': 954,\n",
       " '满载': 955,\n",
       " '多点': 956,\n",
       " '机械': 957,\n",
       " '一起': 958,\n",
       " '三个': 959,\n",
       " '宽': 960,\n",
       " '几乎': 961,\n",
       " '没法': 962,\n",
       " '索': 963,\n",
       " '19': 964,\n",
       " '超级': 965,\n",
       " '正时': 966,\n",
       " '整体': 967,\n",
       " '巡航': 968,\n",
       " '格': 969,\n",
       " '米': 970,\n",
       " '距离': 971,\n",
       " '断': 972,\n",
       " '可靠性': 973,\n",
       " 'D': 974,\n",
       " '多少钱': 975,\n",
       " '五': 976,\n",
       " '档次': 977,\n",
       " '水': 978,\n",
       " '三元': 979,\n",
       " '实惠': 980,\n",
       " '玩': 981,\n",
       " '导致': 982,\n",
       " '添加': 983,\n",
       " '经济': 984,\n",
       " '挂': 985,\n",
       " '下坡': 986,\n",
       " '肉': 987,\n",
       " '安静': 988,\n",
       " '难道': 989,\n",
       " '有时': 990,\n",
       " '刹': 991,\n",
       " '抓': 992,\n",
       " '很少': 993,\n",
       " '进': 994,\n",
       " '全车': 995,\n",
       " '你们': 996,\n",
       " '已': 997,\n",
       " '薄': 998,\n",
       " '电脑': 999,\n",
       " '完美': 1000,\n",
       " ...}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0  1  0  0  0  1 -1  0  0  1  0  0  0  0  0  0 -1  0  0 -1]\n",
      "[[0, 1, 0], [0, 0, 1], [0, 1, 0], [0, 1, 0], [0, 1, 0], [0, 0, 1], [1, 0, 0], [0, 1, 0], [0, 1, 0], [0, 0, 1], [0, 1, 0], [0, 1, 0], [0, 1, 0], [0, 1, 0], [0, 1, 0], [0, 1, 0], [1, 0, 0], [0, 1, 0], [0, 1, 0], [1, 0, 0]]\n"
     ]
    }
   ],
   "source": [
    "from keras.utils import to_categorical\n",
    "#对数据进行分割\n",
    "#先打乱\n",
    "indices = np.arange(data.shape[0])\n",
    "np.random.shuffle(indices)\n",
    "data = data[indices]\n",
    "labels = labels[indices]\n",
    "print(labels[:20])\n",
    "\n",
    "label = []\n",
    "for i in range(len(labels)):\n",
    "    if labels[i] == 0:\n",
    "        label.append([0, 1 , 0])\n",
    "    elif labels[i] == -1:\n",
    "        label.append([1, 0, 0])\n",
    "    elif labels[i] == 1:\n",
    "        label.append([0, 0, 1])\n",
    "print(label[:20])\n",
    "label = np.asarray(label)\n",
    "\n",
    "\n",
    "x_train = data[:training_sample]\n",
    "y_train = label[:training_sample]\n",
    "x_val = data[training_sample: training_sample + validation_samples]\n",
    "y_val = label[training_sample: training_sample + validation_samples]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7957, 30)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7957, 3)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "merge_1 (Merge)              (None, 30, 9)             0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_1 ( (None, 9)                 0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                100       \n",
      "=================================================================\n",
      "Total params: 2,155,876\n",
      "Trainable params: 2,155,876\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:24: UserWarning: The `Merge` layer is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras import layers\n",
    "\n",
    "max_words = 10000\n",
    "embedding_dims = 100\n",
    "maxlen = 30\n",
    "filters = 128\n",
    "kernel_size = 3\n",
    "\n",
    "right_branch = Sequential()\n",
    "right_branch.add(layers.Embedding(max_words, embedding_dims, input_length=maxlen))\n",
    "right_branch.add(layers.Conv1D(filters=filters,\n",
    "                                    kernel_size=kernel_size,\n",
    "                                    padding='valid',\n",
    "                                    activation='relu',\n",
    "                                     ))\n",
    "right_branch.add(layers.MaxPooling1D(3))\n",
    "\n",
    "\n",
    "left_branch = Sequential()\n",
    "left_branch.add(layers.Embedding(max_words, embedding_dims, input_length=maxlen))\n",
    "left_branch.add(layers.LSTM(128, return_sequences=True))\n",
    "\n",
    "merged = layers.Merge([left_branch, right_branch], mode='dot', output_shape=lambda x: x[0])\n",
    "\n",
    "final_model = Sequential()\n",
    "final_model.add(merged)\n",
    "final_model.add(layers.GlobalAveragePooling1D())\n",
    "final_model.add(layers.Dense(10, activation='softmax'))\n",
    "\n",
    "final_model.summary()\n",
    "#right_branch.summary()\n",
    "\n",
    "#model.add(layers.MaxPooling1D(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7957 samples, validate on 1990 samples\n",
      "Epoch 1/100\n",
      "7957/7957 [==============================] - 15s 2ms/step - loss: 0.7568 - acc: 0.7588 - val_loss: 3.8335 - val_acc: 0.1673\n",
      "Epoch 2/100\n",
      "7957/7957 [==============================] - 14s 2ms/step - loss: 0.6977 - acc: 0.7763 - val_loss: 4.0358 - val_acc: 0.1824\n",
      "Epoch 3/100\n",
      "7957/7957 [==============================] - 15s 2ms/step - loss: 0.6666 - acc: 0.7836 - val_loss: 3.8526 - val_acc: 0.1281\n",
      "Epoch 4/100\n",
      "7957/7957 [==============================] - 15s 2ms/step - loss: 0.6336 - acc: 0.7901 - val_loss: 3.9543 - val_acc: 0.1296\n",
      "Epoch 5/100\n",
      "7957/7957 [==============================] - 13s 2ms/step - loss: 0.6102 - acc: 0.7962 - val_loss: 4.2222 - val_acc: 0.1704\n",
      "Epoch 6/100\n",
      "7957/7957 [==============================] - 13s 2ms/step - loss: 0.5869 - acc: 0.7985 - val_loss: 4.0655 - val_acc: 0.1367\n",
      "Epoch 7/100\n",
      "7957/7957 [==============================] - 13s 2ms/step - loss: 0.5700 - acc: 0.8048 - val_loss: 4.0767 - val_acc: 0.1487\n",
      "Epoch 8/100\n",
      "7957/7957 [==============================] - 13s 2ms/step - loss: 0.5510 - acc: 0.8078 - val_loss: 4.0536 - val_acc: 0.1367\n",
      "Epoch 9/100\n",
      "7957/7957 [==============================] - 13s 2ms/step - loss: 0.5301 - acc: 0.8127 - val_loss: 4.0840 - val_acc: 0.1337\n",
      "Epoch 10/100\n",
      "7957/7957 [==============================] - 13s 2ms/step - loss: 0.5200 - acc: 0.8150 - val_loss: 4.2905 - val_acc: 0.1658\n",
      "Epoch 11/100\n",
      "7957/7957 [==============================] - 12s 2ms/step - loss: 0.5070 - acc: 0.8145 - val_loss: 4.1110 - val_acc: 0.1543\n",
      "Epoch 12/100\n",
      "7957/7957 [==============================] - 12s 2ms/step - loss: 0.4918 - acc: 0.8179 - val_loss: 4.1817 - val_acc: 0.1447\n",
      "Epoch 13/100\n",
      "7957/7957 [==============================] - 13s 2ms/step - loss: 0.4805 - acc: 0.8215 - val_loss: 4.3824 - val_acc: 0.1538\n",
      "Epoch 14/100\n",
      "7957/7957 [==============================] - 13s 2ms/step - loss: 0.4684 - acc: 0.8248 - val_loss: 4.4554 - val_acc: 0.1533\n",
      "Epoch 15/100\n",
      "7957/7957 [==============================] - 13s 2ms/step - loss: 0.4622 - acc: 0.8261 - val_loss: 4.2855 - val_acc: 0.1568\n",
      "Epoch 16/100\n",
      "7957/7957 [==============================] - 13s 2ms/step - loss: 0.4524 - acc: 0.8246 - val_loss: 4.2206 - val_acc: 0.1352\n",
      "Epoch 17/100\n",
      "7957/7957 [==============================] - 13s 2ms/step - loss: 0.4422 - acc: 0.8271 - val_loss: 4.3058 - val_acc: 0.1487\n",
      "Epoch 18/100\n",
      "7957/7957 [==============================] - 13s 2ms/step - loss: 0.4392 - acc: 0.8281 - val_loss: 4.4150 - val_acc: 0.1628\n",
      "Epoch 19/100\n",
      "7957/7957 [==============================] - 13s 2ms/step - loss: 0.4297 - acc: 0.8268 - val_loss: 4.4820 - val_acc: 0.1412\n",
      "Epoch 20/100\n",
      "7957/7957 [==============================] - 15s 2ms/step - loss: 0.4233 - acc: 0.8276 - val_loss: 4.4740 - val_acc: 0.1578\n",
      "Epoch 21/100\n",
      "7957/7957 [==============================] - 13s 2ms/step - loss: 0.4182 - acc: 0.8253 - val_loss: 4.7559 - val_acc: 0.1563\n",
      "Epoch 22/100\n",
      "7957/7957 [==============================] - 13s 2ms/step - loss: 0.4132 - acc: 0.8327 - val_loss: 4.6583 - val_acc: 0.1412\n",
      "Epoch 23/100\n",
      "7957/7957 [==============================] - 12s 2ms/step - loss: 0.4103 - acc: 0.8287 - val_loss: 4.6476 - val_acc: 0.1518\n",
      "Epoch 24/100\n",
      "7957/7957 [==============================] - 12s 2ms/step - loss: 0.4014 - acc: 0.8315 - val_loss: 4.7079 - val_acc: 0.1417\n",
      "Epoch 25/100\n",
      "7957/7957 [==============================] - 12s 2ms/step - loss: 0.4033 - acc: 0.8288 - val_loss: 4.4729 - val_acc: 0.1397\n",
      "Epoch 26/100\n",
      "7957/7957 [==============================] - 12s 2ms/step - loss: 0.3968 - acc: 0.8334 - val_loss: 4.7056 - val_acc: 0.1447\n",
      "Epoch 27/100\n",
      "7957/7957 [==============================] - 13s 2ms/step - loss: 0.3934 - acc: 0.8282 - val_loss: 4.8366 - val_acc: 0.1613\n",
      "Epoch 28/100\n",
      "7957/7957 [==============================] - 13s 2ms/step - loss: 0.3889 - acc: 0.8320 - val_loss: 4.8486 - val_acc: 0.1407\n",
      "Epoch 29/100\n",
      "7957/7957 [==============================] - 13s 2ms/step - loss: 0.3860 - acc: 0.8329 - val_loss: 4.6401 - val_acc: 0.1432\n",
      "Epoch 30/100\n",
      "7957/7957 [==============================] - 12s 2ms/step - loss: 0.3829 - acc: 0.8322 - val_loss: 5.1156 - val_acc: 0.1432\n",
      "Epoch 31/100\n",
      "7957/7957 [==============================] - 13s 2ms/step - loss: 0.3789 - acc: 0.8332 - val_loss: 4.8213 - val_acc: 0.1518\n",
      "Epoch 32/100\n",
      "7957/7957 [==============================] - 13s 2ms/step - loss: 0.3743 - acc: 0.8349 - val_loss: 5.0798 - val_acc: 0.1533\n",
      "Epoch 33/100\n",
      "7957/7957 [==============================] - 13s 2ms/step - loss: 0.3758 - acc: 0.8305 - val_loss: 4.8081 - val_acc: 0.1332\n",
      "Epoch 34/100\n",
      "7957/7957 [==============================] - 13s 2ms/step - loss: 0.3741 - acc: 0.8344 - val_loss: 4.8085 - val_acc: 0.1427\n",
      "Epoch 35/100\n",
      "7957/7957 [==============================] - 12s 2ms/step - loss: 0.3716 - acc: 0.8349 - val_loss: 4.9200 - val_acc: 0.1447\n",
      "Epoch 36/100\n",
      "7957/7957 [==============================] - 12s 2ms/step - loss: 0.3671 - acc: 0.8335 - val_loss: 4.8299 - val_acc: 0.1568\n",
      "Epoch 37/100\n",
      "7957/7957 [==============================] - 12s 2ms/step - loss: 0.3685 - acc: 0.8337 - val_loss: 5.1650 - val_acc: 0.1437\n",
      "Epoch 38/100\n",
      "7957/7957 [==============================] - 12s 2ms/step - loss: 0.3597 - acc: 0.8355 - val_loss: 5.1564 - val_acc: 0.1387\n",
      "Epoch 39/100\n",
      "7957/7957 [==============================] - 12s 2ms/step - loss: 0.3623 - acc: 0.8331 - val_loss: 4.7347 - val_acc: 0.1447\n",
      "Epoch 40/100\n",
      "7957/7957 [==============================] - 12s 2ms/step - loss: 0.3593 - acc: 0.8336 - val_loss: 4.9319 - val_acc: 0.1457\n",
      "Epoch 41/100\n",
      "7957/7957 [==============================] - 12s 2ms/step - loss: 0.3599 - acc: 0.8332 - val_loss: 4.8967 - val_acc: 0.1492\n",
      "Epoch 42/100\n",
      "7957/7957 [==============================] - 12s 2ms/step - loss: 0.3568 - acc: 0.8357 - val_loss: 5.1651 - val_acc: 0.1477\n",
      "Epoch 43/100\n",
      "7957/7957 [==============================] - 12s 2ms/step - loss: 0.3570 - acc: 0.8337 - val_loss: 5.0082 - val_acc: 0.1533\n",
      "Epoch 44/100\n",
      "7957/7957 [==============================] - 12s 2ms/step - loss: 0.3553 - acc: 0.8301 - val_loss: 5.0998 - val_acc: 0.1407\n",
      "Epoch 45/100\n",
      "7957/7957 [==============================] - 12s 2ms/step - loss: 0.3518 - acc: 0.8379 - val_loss: 4.8813 - val_acc: 0.1533\n",
      "Epoch 46/100\n",
      "7957/7957 [==============================] - 12s 2ms/step - loss: 0.3507 - acc: 0.8350 - val_loss: 4.8480 - val_acc: 0.1563\n",
      "Epoch 47/100\n",
      "7957/7957 [==============================] - 12s 2ms/step - loss: 0.3502 - acc: 0.8332 - val_loss: 4.9117 - val_acc: 0.1497\n",
      "Epoch 48/100\n",
      "7957/7957 [==============================] - 12s 2ms/step - loss: 0.3473 - acc: 0.8357 - val_loss: 5.0901 - val_acc: 0.1402\n",
      "Epoch 49/100\n",
      "7957/7957 [==============================] - 12s 2ms/step - loss: 0.3468 - acc: 0.8349 - val_loss: 4.8229 - val_acc: 0.1578\n",
      "Epoch 50/100\n",
      "7957/7957 [==============================] - 12s 2ms/step - loss: 0.3444 - acc: 0.8323 - val_loss: 4.8879 - val_acc: 0.1563\n",
      "Epoch 51/100\n",
      "7957/7957 [==============================] - 12s 2ms/step - loss: 0.3429 - acc: 0.8364 - val_loss: 4.9757 - val_acc: 0.1528\n",
      "Epoch 52/100\n",
      "7957/7957 [==============================] - 12s 2ms/step - loss: 0.3411 - acc: 0.8361 - val_loss: 4.9003 - val_acc: 0.1447\n",
      "Epoch 53/100\n",
      "7957/7957 [==============================] - 12s 2ms/step - loss: 0.3407 - acc: 0.8371 - val_loss: 5.3645 - val_acc: 0.1387\n",
      "Epoch 54/100\n",
      "7957/7957 [==============================] - 12s 2ms/step - loss: 0.3405 - acc: 0.8331 - val_loss: 4.9896 - val_acc: 0.1377\n",
      "Epoch 55/100\n",
      "7957/7957 [==============================] - 13s 2ms/step - loss: 0.3395 - acc: 0.8354 - val_loss: 4.7489 - val_acc: 0.1492\n",
      "Epoch 56/100\n",
      "7957/7957 [==============================] - 12s 2ms/step - loss: 0.3362 - acc: 0.8396 - val_loss: 5.6112 - val_acc: 0.1487\n",
      "Epoch 57/100\n",
      "7957/7957 [==============================] - 12s 2ms/step - loss: 0.3377 - acc: 0.8331 - val_loss: 5.2070 - val_acc: 0.1513\n",
      "Epoch 58/100\n",
      "7957/7957 [==============================] - 12s 2ms/step - loss: 0.3334 - acc: 0.8370 - val_loss: 5.4227 - val_acc: 0.1332\n",
      "Epoch 59/100\n",
      "7957/7957 [==============================] - 12s 2ms/step - loss: 0.3333 - acc: 0.8364 - val_loss: 5.2840 - val_acc: 0.1452\n",
      "Epoch 60/100\n",
      "7957/7957 [==============================] - 12s 1ms/step - loss: 0.3361 - acc: 0.8354 - val_loss: 5.1201 - val_acc: 0.1412\n",
      "Epoch 61/100\n",
      "7957/7957 [==============================] - 12s 2ms/step - loss: 0.3322 - acc: 0.8389 - val_loss: 4.9763 - val_acc: 0.1452\n",
      "Epoch 62/100\n",
      "7957/7957 [==============================] - 12s 2ms/step - loss: 0.3322 - acc: 0.8405 - val_loss: 5.8817 - val_acc: 0.1503\n",
      "Epoch 63/100\n",
      "7957/7957 [==============================] - 12s 1ms/step - loss: 0.3314 - acc: 0.8354 - val_loss: 4.8510 - val_acc: 0.1558\n",
      "Epoch 64/100\n",
      "7957/7957 [==============================] - 12s 2ms/step - loss: 0.3301 - acc: 0.8367 - val_loss: 5.5053 - val_acc: 0.1327\n",
      "Epoch 65/100\n",
      "7957/7957 [==============================] - 12s 2ms/step - loss: 0.3272 - acc: 0.8364 - val_loss: 5.1816 - val_acc: 0.1578\n",
      "Epoch 66/100\n",
      "7957/7957 [==============================] - 12s 2ms/step - loss: 0.3301 - acc: 0.8334 - val_loss: 5.2324 - val_acc: 0.1462\n",
      "Epoch 67/100\n",
      "7957/7957 [==============================] - 12s 2ms/step - loss: 0.3266 - acc: 0.8416 - val_loss: 5.3282 - val_acc: 0.1337\n",
      "Epoch 68/100\n",
      "7957/7957 [==============================] - 12s 1ms/step - loss: 0.3285 - acc: 0.8344 - val_loss: 5.4332 - val_acc: 0.1387\n",
      "Epoch 69/100\n",
      "7957/7957 [==============================] - 12s 1ms/step - loss: 0.3258 - acc: 0.8367 - val_loss: 5.7676 - val_acc: 0.1462\n",
      "Epoch 70/100\n",
      "7957/7957 [==============================] - 12s 2ms/step - loss: 0.3266 - acc: 0.8322 - val_loss: 5.4136 - val_acc: 0.1372\n",
      "Epoch 71/100\n",
      "7957/7957 [==============================] - 13s 2ms/step - loss: 0.3245 - acc: 0.8380 - val_loss: 5.8570 - val_acc: 0.1407\n",
      "Epoch 72/100\n",
      "7957/7957 [==============================] - 12s 2ms/step - loss: 0.3221 - acc: 0.8391 - val_loss: 5.2665 - val_acc: 0.1442\n",
      "Epoch 73/100\n",
      "7957/7957 [==============================] - 12s 2ms/step - loss: 0.3243 - acc: 0.8381 - val_loss: 5.1581 - val_acc: 0.1332\n",
      "Epoch 74/100\n",
      "7957/7957 [==============================] - 12s 2ms/step - loss: 0.3207 - acc: 0.8393 - val_loss: 5.4569 - val_acc: 0.1362\n",
      "Epoch 75/100\n",
      "7957/7957 [==============================] - 12s 2ms/step - loss: 0.3228 - acc: 0.8376 - val_loss: 5.0366 - val_acc: 0.1397\n",
      "Epoch 76/100\n",
      "7957/7957 [==============================] - 12s 2ms/step - loss: 0.3218 - acc: 0.8365 - val_loss: 5.0444 - val_acc: 0.1387\n",
      "Epoch 77/100\n",
      "7957/7957 [==============================] - 12s 2ms/step - loss: 0.3201 - acc: 0.8345 - val_loss: 5.6130 - val_acc: 0.1422\n",
      "Epoch 78/100\n",
      "7957/7957 [==============================] - 12s 2ms/step - loss: 0.3187 - acc: 0.8378 - val_loss: 5.0124 - val_acc: 0.1407\n",
      "Epoch 79/100\n",
      "7957/7957 [==============================] - 12s 2ms/step - loss: 0.3185 - acc: 0.8342 - val_loss: 5.4040 - val_acc: 0.1487\n",
      "Epoch 80/100\n",
      "7957/7957 [==============================] - 12s 1ms/step - loss: 0.3154 - acc: 0.8395 - val_loss: 5.3489 - val_acc: 0.1327\n",
      "Epoch 81/100\n",
      "7957/7957 [==============================] - 12s 2ms/step - loss: 0.3179 - acc: 0.8386 - val_loss: 5.3523 - val_acc: 0.1407\n",
      "Epoch 82/100\n",
      "7957/7957 [==============================] - 12s 2ms/step - loss: 0.3160 - acc: 0.8349 - val_loss: 5.4042 - val_acc: 0.1452\n",
      "Epoch 83/100\n",
      "7957/7957 [==============================] - 12s 2ms/step - loss: 0.3157 - acc: 0.8349 - val_loss: 5.4348 - val_acc: 0.1482\n",
      "Epoch 84/100\n",
      "7957/7957 [==============================] - 12s 2ms/step - loss: 0.3115 - acc: 0.8359 - val_loss: 5.5230 - val_acc: 0.1362\n",
      "Epoch 85/100\n",
      "7957/7957 [==============================] - 12s 2ms/step - loss: 0.3126 - acc: 0.8345 - val_loss: 5.3012 - val_acc: 0.1382\n",
      "Epoch 86/100\n",
      "7957/7957 [==============================] - 12s 2ms/step - loss: 0.3140 - acc: 0.8378 - val_loss: 5.0301 - val_acc: 0.1352\n",
      "Epoch 87/100\n",
      "7957/7957 [==============================] - 12s 2ms/step - loss: 0.3119 - acc: 0.8373 - val_loss: 5.7357 - val_acc: 0.1357\n",
      "Epoch 88/100\n",
      "7957/7957 [==============================] - 12s 2ms/step - loss: 0.3115 - acc: 0.8391 - val_loss: 5.4202 - val_acc: 0.1347\n",
      "Epoch 89/100\n",
      "7957/7957 [==============================] - 12s 2ms/step - loss: 0.3090 - acc: 0.8378 - val_loss: 5.7021 - val_acc: 0.1266\n",
      "Epoch 90/100\n",
      "7957/7957 [==============================] - 12s 2ms/step - loss: 0.3104 - acc: 0.8366 - val_loss: 5.1417 - val_acc: 0.1447\n",
      "Epoch 91/100\n",
      "7957/7957 [==============================] - 12s 2ms/step - loss: 0.3106 - acc: 0.8393 - val_loss: 5.4232 - val_acc: 0.1402\n",
      "Epoch 92/100\n",
      "7957/7957 [==============================] - 12s 2ms/step - loss: 0.3094 - acc: 0.8393 - val_loss: 5.4120 - val_acc: 0.1327\n",
      "Epoch 93/100\n",
      "7957/7957 [==============================] - 12s 2ms/step - loss: 0.3070 - acc: 0.8362 - val_loss: 5.5089 - val_acc: 0.1487\n",
      "Epoch 94/100\n",
      "7957/7957 [==============================] - 12s 2ms/step - loss: 0.3086 - acc: 0.8390 - val_loss: 4.8882 - val_acc: 0.1467\n",
      "Epoch 95/100\n",
      "7957/7957 [==============================] - 12s 2ms/step - loss: 0.3085 - acc: 0.8360 - val_loss: 5.8286 - val_acc: 0.1417\n",
      "Epoch 96/100\n",
      "7957/7957 [==============================] - 12s 1ms/step - loss: 0.3068 - acc: 0.8379 - val_loss: 5.4225 - val_acc: 0.1487\n",
      "Epoch 97/100\n",
      "7957/7957 [==============================] - 12s 2ms/step - loss: 0.3075 - acc: 0.8386 - val_loss: 5.5713 - val_acc: 0.1397\n",
      "Epoch 98/100\n",
      "7957/7957 [==============================] - 12s 2ms/step - loss: 0.3045 - acc: 0.8360 - val_loss: 5.6595 - val_acc: 0.1317\n",
      "Epoch 99/100\n",
      "7957/7957 [==============================] - 12s 2ms/step - loss: 0.3067 - acc: 0.8376 - val_loss: 4.9894 - val_acc: 0.1372\n",
      "Epoch 100/100\n",
      "7957/7957 [==============================] - 12s 1ms/step - loss: 0.3044 - acc: 0.8380 - val_loss: 5.5760 - val_acc: 0.1231\n"
     ]
    }
   ],
   "source": [
    "final_model.compile(optimizer='rmsprop',\n",
    "             loss='categorical_crossentropy',\n",
    "             metrics=['acc'])\n",
    "history = final_model.fit([x_train,x_train], y_train_subject,\n",
    "                   epochs=100,\n",
    "                   batch_size=32,\n",
    "                   validation_data=([x_val,x_val], y_test_subject),\n",
    "                   #callbacks=callback_list,\n",
    "                    verbose =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From F:\\Anaconda\\envs\\tensorflow-gpu\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:1242: calling reduce_sum (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 30, 100)           1000000   \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 128)               84480     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 32)                4128      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                330       \n",
      "=================================================================\n",
      "Total params: 1,088,938\n",
      "Trainable params: 1,088,938\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras import layers\n",
    "\n",
    "#【max_words单词， embedding_dims单词对应的维度向量】\n",
    "embedding_dim = 100\n",
    "\n",
    "\n",
    "# 定义模型\n",
    "#【样本，每个样本100单词，每个单词100维度】\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, Flatten, Dense, Bidirectional, LSTM\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_words, embedding_dim, input_length=maxlen))#构建词嵌入，每个单词\n",
    "# model.add(layers.Conv1D(32, 5, activation='relu'))\n",
    "# model.add(layers.MaxPooling1D(3))\n",
    "model.add(Bidirectional(LSTM(64)))\n",
    "#model.add(Flatten())\n",
    "model.add(Dense(32, activation='relu'))#负责单词之间的练习和语义\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "\n",
    "y_train_subject = raw_data['subject'][:training_sample]\n",
    "y_test_subject = raw_data['subject'][training_sample:]\n",
    "\n",
    "\n",
    "y_test_subject = to_categorical(y_test_subject, num_classes=10)\n",
    "y_train_subject = to_categorical(y_train_subject, num_classes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7957, 10)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_subject.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1990, 10)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_subject.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From F:\\Anaconda\\envs\\tensorflow-gpu\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:1344: calling reduce_mean (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "Train on 7957 samples, validate on 1990 samples\n",
      "Epoch 1/10\n",
      "7957/7957 [==============================] - 28s 3ms/step - loss: 2.1452 - acc: 0.2718 - val_loss: 2.2079 - val_acc: 0.2804\n",
      "Epoch 2/10\n",
      "7957/7957 [==============================] - 24s 3ms/step - loss: 2.1083 - acc: 0.2756 - val_loss: 2.2457 - val_acc: 0.2709\n",
      "Epoch 3/10\n",
      "7957/7957 [==============================] - 25s 3ms/step - loss: 1.9911 - acc: 0.3133 - val_loss: 2.3263 - val_acc: 0.1628\n",
      "Epoch 4/10\n",
      "7957/7957 [==============================] - 25s 3ms/step - loss: 1.8073 - acc: 0.3759 - val_loss: 2.4419 - val_acc: 0.1653\n",
      "Epoch 5/10\n",
      "7957/7957 [==============================] - 26s 3ms/step - loss: 1.6118 - acc: 0.4500 - val_loss: 2.5578 - val_acc: 0.1613\n",
      "Epoch 6/10\n",
      "7957/7957 [==============================] - 28s 4ms/step - loss: 1.4233 - acc: 0.5198 - val_loss: 3.0715 - val_acc: 0.1613\n",
      "Epoch 7/10\n",
      "7957/7957 [==============================] - 25s 3ms/step - loss: 1.2573 - acc: 0.5805 - val_loss: 3.1519 - val_acc: 0.1302\n",
      "Epoch 8/10\n",
      "7957/7957 [==============================] - 26s 3ms/step - loss: 1.1169 - acc: 0.6323 - val_loss: 3.1179 - val_acc: 0.1764\n",
      "Epoch 9/10\n",
      "7957/7957 [==============================] - 25s 3ms/step - loss: 0.9845 - acc: 0.6776 - val_loss: 3.7209 - val_acc: 0.1477\n",
      "Epoch 10/10\n",
      "7957/7957 [==============================] - 25s 3ms/step - loss: 0.8781 - acc: 0.7082 - val_loss: 4.0108 - val_acc: 0.1437\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "model.compile(optimizer='rmsprop',\n",
    "             loss='categorical_crossentropy',\n",
    "             metrics=['acc'])\n",
    "history = model.fit(x_train, y_train_subject,\n",
    "                   epochs=10,\n",
    "                   batch_size=32,\n",
    "                   validation_data=(x_val, y_test_subject),\n",
    "                   #callbacks=callback_list,\n",
    "                    verbose =1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From F:\\Anaconda\\envs\\tensorflow-gpu\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:1242: calling reduce_sum (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 30, 100)           1000000   \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 30, 32)            17024     \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 64)                24832     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 3)                 99        \n",
      "=================================================================\n",
      "Total params: 1,044,035\n",
      "Trainable params: 1,044,035\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#【样本，每个样本30单词，每个单词100维度】\n",
    "from keras import layers\n",
    "from keras.models import Sequential\n",
    "embedding_dims = 100\n",
    "\n",
    "# 定义模型\n",
    "model_1 = Sequential()\n",
    "model_1.add(layers.Embedding(max_words, embedding_dims, input_length=maxlen))#构建词嵌入，每个单词\n",
    "model_1.add(layers.LSTM(32,\n",
    "                      dropout=0.1,\n",
    "                      recurrent_dropout=0.5,\n",
    "                      return_sequences=True,\n",
    "                     ))\n",
    "model_1.add(layers.LSTM(64,\n",
    "                     activation='relu',\n",
    "                      dropout=0.1,\n",
    "                      recurrent_dropout=0.5,\n",
    "                     ))\n",
    "#model.add(layers.Flatten())# 3 -> 2\n",
    "model_1.add(layers.Dense(32, activation='relu'))#负责单词之间的练习和语义\n",
    "model_1.add(layers.Dense(3, activation='softmax'))\n",
    "model_1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7957 samples, validate on 1990 samples\n",
      "Epoch 1/10\n",
      "7957/7957 [==============================] - 31s 4ms/step - loss: 0.6872 - acc: 0.7206 - val_loss: 0.7480 - val_acc: 0.7070\n",
      "Epoch 2/10\n",
      "7957/7957 [==============================] - 27s 3ms/step - loss: 0.6191 - acc: 0.7577 - val_loss: 0.8277 - val_acc: 0.6271\n",
      "Epoch 3/10\n",
      "7957/7957 [==============================] - 27s 3ms/step - loss: 0.5634 - acc: 0.7860 - val_loss: 0.7649 - val_acc: 0.7090\n",
      "Epoch 4/10\n",
      "7957/7957 [==============================] - 28s 4ms/step - loss: 0.5095 - acc: 0.8042 - val_loss: 0.8077 - val_acc: 0.6915\n",
      "Epoch 5/10\n",
      "7957/7957 [==============================] - 28s 3ms/step - loss: 0.4683 - acc: 0.8242 - val_loss: 0.8504 - val_acc: 0.7211\n",
      "Epoch 6/10\n",
      "7957/7957 [==============================] - 28s 3ms/step - loss: 0.4261 - acc: 0.8422 - val_loss: 0.9042 - val_acc: 0.6302\n",
      "Epoch 7/10\n",
      "7957/7957 [==============================] - 28s 4ms/step - loss: 0.3897 - acc: 0.8569 - val_loss: 0.8788 - val_acc: 0.7050\n",
      "Epoch 8/10\n",
      "7957/7957 [==============================] - 27s 3ms/step - loss: 0.3611 - acc: 0.8716 - val_loss: 0.9288 - val_acc: 0.6829\n",
      "Epoch 9/10\n",
      "7957/7957 [==============================] - 27s 3ms/step - loss: 0.3392 - acc: 0.8761 - val_loss: 0.9064 - val_acc: 0.6518\n",
      "Epoch 10/10\n",
      "7957/7957 [==============================] - 27s 3ms/step - loss: 0.3103 - acc: 0.8897 - val_loss: 1.0951 - val_acc: 0.6568\n"
     ]
    }
   ],
   "source": [
    "model_1.compile(optimizer='rmsprop',\n",
    "             loss='categorical_crossentropy',\n",
    "             metrics=['acc'])\n",
    "history = model_1.fit(x_train, y_train,\n",
    "                   epochs=10,\n",
    "                   batch_size=32,\n",
    "                   validation_data=(x_val, y_val),\n",
    "                   callbacks=callback_list,\n",
    "                    verbose =1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.callbacks import TensorBoard, ReduceLROnPlateau, EarlyStopping, ModelCheckpoint\n",
    "\n",
    "\n",
    "class Callback(object):\n",
    "    def __init__(self, model_name):\n",
    "        self.model_name = model_name\n",
    "        self.log_dir = \"{}_logs/\".format(self.model_name)\n",
    "        self.model_dir = \"{}_models/\".format(self.model_name)\n",
    "\n",
    "    def get_tensorboard(self):#是一个可视化的展示器\n",
    "        tensorboard_callback = TensorBoard(log_dir=self.log_dir, write_grads=True,\n",
    "                                           histogram_freq=0, write_images=True)\n",
    "        return tensorboard_callback\n",
    "\n",
    "    def get_early_stop(self, patience):#当监测值不再改善时，该回调函数将中止训练\n",
    "        early_stop = EarlyStopping('val_acc', patience=patience)\n",
    "        return early_stop\n",
    "\n",
    "    def get_readuce_lr(self, factor, patience):#学习率衰减\n",
    "        return ReduceLROnPlateau(monitor='val_acc', factor=factor, patience=patience)\n",
    "\n",
    "    def get_model_ckpt(self):#在每个epoch后保存模型\n",
    "        model_names = self.model_dir + '.{epoch:02d}-{val_acc:.4f}.h5'\n",
    "        model_checkpoint = ModelCheckpoint(model_names, monitor='val_acc', verbose=1, save_best_only=True)\n",
    "        return model_checkpoint\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "callbacks = Callback('LSTM')\n",
    "tensorboard = callbacks.get_tensorboard()\n",
    "early_stop = callbacks.get_early_stop(5)\n",
    "readuce_lr = callbacks.get_readuce_lr(factor=0.5, patience=50 // 4)\n",
    "#model_ckpt = callbacks.get_model_ckpt()\n",
    "callback_list = [tensorboard, early_stop, readuce_lr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7957 samples, validate on 1990 samples\n",
      "Epoch 1/10\n",
      "7957/7957 [==============================] - 25s 3ms/step - loss: 0.8147 - acc: 0.6692 - val_loss: 0.7670 - val_acc: 0.6960\n",
      "Epoch 2/10\n",
      "7957/7957 [==============================] - 23s 3ms/step - loss: 0.7135 - acc: 0.7030 - val_loss: 0.7853 - val_acc: 0.7005\n",
      "Epoch 3/10\n",
      "7957/7957 [==============================] - 23s 3ms/step - loss: 0.6324 - acc: 0.7444 - val_loss: 0.7621 - val_acc: 0.7090\n",
      "Epoch 4/10\n",
      "7957/7957 [==============================] - 23s 3ms/step - loss: 0.5295 - acc: 0.7939 - val_loss: 0.7568 - val_acc: 0.6980\n",
      "Epoch 5/10\n",
      "6560/7957 [=======================>......] - ETA: 3s - loss: 0.4399 - acc: 0.8294"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-26-599889b1a909>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      6\u001b[0m                    \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m                    \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m                    \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcallback_list\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m )\n",
      "\u001b[1;32mF:\\Anaconda\\envs\\tensorflow-gpu\\lib\\site-packages\\keras\\models.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m    958\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    959\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 960\u001b[1;33m                               validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m    961\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    962\u001b[0m     def evaluate(self, x, y, batch_size=32, verbose=1,\n",
      "\u001b[1;32mF:\\Anaconda\\envs\\tensorflow-gpu\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m   1646\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1647\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1648\u001b[1;33m                               validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m   1649\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1650\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[1;32mF:\\Anaconda\\envs\\tensorflow-gpu\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[1;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[0;32m   1211\u001b[0m                     \u001b[0mbatch_logs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'size'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1212\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1213\u001b[1;33m                     \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1214\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1215\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\Anaconda\\envs\\tensorflow-gpu\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2350\u001b[0m         \u001b[0msession\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2351\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[1;32m-> 2352\u001b[1;33m                               **self.session_kwargs)\n\u001b[0m\u001b[0;32m   2353\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2354\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\Anaconda\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    875\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    876\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 877\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    878\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    879\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\Anaconda\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1098\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1099\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1100\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1101\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1102\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\Anaconda\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1270\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1271\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[1;32m-> 1272\u001b[1;33m                            run_metadata)\n\u001b[0m\u001b[0;32m   1273\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1274\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\Anaconda\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1276\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1277\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1278\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1279\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1280\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\Anaconda\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1261\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1262\u001b[0m       return self._call_tf_sessionrun(\n\u001b[1;32m-> 1263\u001b[1;33m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[0;32m   1264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1265\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\Anaconda\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[1;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[0;32m   1348\u001b[0m     return tf_session.TF_SessionRun_wrapper(\n\u001b[0;32m   1349\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1350\u001b[1;33m         run_metadata)\n\u001b[0m\u001b[0;32m   1351\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1352\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='rmsprop',\n",
    "             loss='categorical_crossentropy',\n",
    "             metrics=['acc'])\n",
    "history = model.fit(x_train, y_train,\n",
    "                   epochs=10,\n",
    "                   batch_size=32,\n",
    "                   validation_data=(x_val, y_val),\n",
    "                   callbacks=callback_list\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAEICAYAAABYoZ8gAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1519aa07d30>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAEICAYAAACktLTqAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nkTT0/1baJUQmrwlBAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1519aefa828>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#绘制模型随时间的变化\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "plt.plot(epochs, acc, 'bo', label = 'Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label = 'Validation acc')\n",
    "plt.title('Training and Validation accuracy')\n",
    "plt.legend()#显示图例\n",
    "\n",
    "plt.figure()#创建窗口\n",
    "\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and Validation loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "svm_clf = LinearSVC(LinearSVC(C=1, loss=\"hinge\", random_state=42))\n",
    "svm_clf.fit(data, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnicodeDecodeError",
     "evalue": "'utf-8' codec can't decode byte 0xc4 in position 0: invalid continuation byte",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._convert_tokens (pandas\\_libs\\parsers.c:14858)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._convert_with_dtype (pandas\\_libs\\parsers.c:17119)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._string_convert (pandas\\_libs\\parsers.c:17347)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers._string_box_utf8 (pandas\\_libs\\parsers.c:23041)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m: 'utf-8' codec can't decode byte 0xc4 in position 0: invalid continuation byte",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-fd9515ef533f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mcompare1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'submit_svc.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mcompare2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'submit_logistic.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcompare1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcompare2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\Anaconda\\envs\\tensorflow-gpu\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, skipfooter, skip_footer, doublequote, delim_whitespace, as_recarray, compact_ints, use_unsigned, low_memory, buffer_lines, memory_map, float_precision)\u001b[0m\n\u001b[0;32m    653\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[0;32m    654\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 655\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    656\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    657\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\Anaconda\\envs\\tensorflow-gpu\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    409\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    410\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 411\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    412\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    413\u001b[0m         \u001b[0mparser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\Anaconda\\envs\\tensorflow-gpu\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m   1003\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'skipfooter not supported for iteration'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1004\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1005\u001b[1;33m         \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1006\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1007\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'as_recarray'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\Anaconda\\envs\\tensorflow-gpu\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m   1746\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1747\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1748\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1749\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1750\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_first_chunk\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.read (pandas\\_libs\\parsers.c:10862)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_low_memory (pandas\\_libs\\parsers.c:11138)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows (pandas\\_libs\\parsers.c:12175)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._convert_column_data (pandas\\_libs\\parsers.c:14136)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._convert_tokens (pandas\\_libs\\parsers.c:14972)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._convert_with_dtype (pandas\\_libs\\parsers.c:17119)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._string_convert (pandas\\_libs\\parsers.c:17347)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers._string_box_utf8 (pandas\\_libs\\parsers.c:23041)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m: 'utf-8' codec can't decode byte 0xc4 in position 0: invalid continuation byte"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "compare1 = pd.read_csv('submit_svc.csv')\n",
    "compare2 = pd.read_csv('submit_logistic.csv')\n",
    "print(compare1.shape)\n",
    "print(compare2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow-gpu",
   "language": "python",
   "name": "tensorflow-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
